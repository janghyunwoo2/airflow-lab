# 7\. KubernetesPodOperator 소개

## 🎯 목표

- KubernetesPodOperator가 **왜 필요한지** 이해한다
- 어떤 경우에 PythonOperator 대신 사용하는지 구분한다
- Airflow + Kubernetes 기반 아키텍처의 큰 그림을 이해한다

* * *

## 📌 왜 KubernetesPodOperator가 필요한가?

지금까지 실습한 방식은 모두:

- Airflow 컨테이너 **내부에서**
- Python 코드 또는 Bash 명령을 실행

하지만 실무에서는 다음과 같은 요구가 자주 등장한다.

- 라이브러리가 너무 많거나 무거운 작업
- GPU, 대용량 메모리가 필요한 작업
- 작업별로 **완전히 다른 실행 환경**이 필요한 경우
- ML 학습 / 대규모 배치 / 외부 툴 실행

이럴 때 사용하는 것이 **KubernetesPodOperator**다.

* * *

## 🧩 KubernetesPodOperator 개념

> **Task 하나를 Kubernetes Pod 하나로 실행하는 Operator**

- Task 실행 시:
    - 새로운 Pod 생성
    - 지정한 Docker Image로 컨테이너 실행
    - 작업 종료 후 Pod 삭제 (옵션)

즉,

- Airflow = **오케스트레이터**
- KubernetesPodOperator = **외부 실행기**

* * *

## 📐 실행 구조 개념도

```text
Airflow Scheduler
      |
      v
KubernetesPodOperator
      |
      v
[ Kubernetes Pod ]
    - Custom Image
    - Custom Resources (CPU / MEM / GPU)
    - Isolated Environment
```

* * *

## 🆚 PythonOperator / TaskFlow API와의 차이

| 구분  | PythonOperator / @task | KubernetesPodOperator |
| --- | --- | --- |
| 실행 위치 | Airflow 컨테이너 내부 | 별도의 Kubernetes Pod |
| 환경 격리 | 약함  | 강함  |
| 라이브러리 | Airflow 이미지에 의존 | 이미지별 완전 분리 |
| 리소스 지정 | 제한적 | CPU / Memory / GPU 지정 가능 |
| 주 사용처 | 가벼운 ETL | ML, 대규모 배치, 특수 작업 |

* * *

## 🧪 언제 사용하면 좋은가?

다음 중 하나라도 해당하면 고려 대상이다.

- 작업 실행 시간이 수 분 이상
- Python 패키지가 많아 Airflow 이미지가 비대해짐
- 팀별 / 작업별 실행 환경이 다름
- ML 학습 / 대규모 데이터 처리
- 실패 시 Airflow 전체 안정성에 영향을 주면 안 되는 작업

* * *

## ⚠️ 왜 이번 강의에서는 실습을 하지 않는가?

KubernetesPodOperator 실습에는 다음 준비가 필요하다.

- Kubernetes 클러스터 (EKS, GKE 등)
- 이미지 레지스트리 (ECR, GCR, GHCR 등)
- RBAC / ServiceAccount 설정
- 네트워크 / 로그 / 스토리지 이해

<br>